{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ab431-1624-4cbe-a084-4df48540be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callback.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b716e-ab7b-4f17-9b30-966885ce78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791bb0d-58eb-48ce-917b-0748ddbed609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai_annotated.foundations import DocumentedEnum, noop\n",
    "\n",
    "from fastcore.basics import mk_class, class2attr, GetAttr, Stateful, store_attr, detuplify\n",
    "from fastcore.foundation import L\n",
    "from fastcore.meta import funcs_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd11fb2-51ac-4dc4-b93f-b7e72fd315bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Events(DocumentedEnum):\n",
    "    \"All possible Callback events\"\n",
    "    after_create = \"Called after the `Learner` is created\"\n",
    "    before_fit = \"Called before starting training or inference, ideal for initial setup\"\n",
    "    before_epoch = \"Called at the beginning of each epoch, useful for any behavior you need to reset at each epoch\"\n",
    "    before_train = \"Called at the beginning of each training part of an epoch\"\n",
    "    before_batch = \"Called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance).\"\n",
    "    after_pred = \"Called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss.\"\n",
    "    after_loss = \"Called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance).\"\n",
    "    before_backward = \"Called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)\"\n",
    "    before_step = \"Called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance).\"\n",
    "    after_step = \"Called after the step and before the gradients are zeroed.\"\n",
    "    after_batch = \"Called at the end of a batch, for any clean-up before the next one.\"\n",
    "    after_cancel_train = \"Reached immediately after a `CancelTrainException` before proceeding to `after_epoch`\"\n",
    "    after_train = \"Called at the end of the training phase of an epoch.\"\n",
    "    before_validate = \"Called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation.\"\n",
    "    after_cancel_validate = \"Reached immediately after a `CancelValidException` before proceeding to `after_epoch`\"\n",
    "    after_validate = \"Called at the end of the validation part of an epoch.\"\n",
    "    after_cancel_epoch = \"Reached immediately after a `CancelEpochException` before proceeding to `after_epoch`\"\n",
    "    after_epoch = \"Called at the end of an epoch, for any clean-up before the next one.\"\n",
    "    after_cancel_fit = \"Reached immediately after a `CancelFitException` before proceeding to `after_fit`\"\n",
    "    after_fit = \"Called at the end of training, for final clean-up.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5293c-3b65-4855-895e-ef65dd5f0f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"Events\" class=\"doc_header\"><code>class</code> <code>Events</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>Events</code>(**`value`**, **`names`**=*`None`*, **`module`**=*`None`*, **`qualname`**=*`None`*, **`type`**=*`None`*, **`start`**=*`1`*) :: [`DocumentedEnum`](/fastai_annotated/core.html#DocumentedEnum)\n",
       "\n",
       "All possible Callback events"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d16cb-8dcf-406d-b47f-bc4b3817f1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_create\" class=\"doc_header\"><code>after_create</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called after the `Learner` is created"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"before_fit\" class=\"doc_header\"><code>before_fit</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called before starting training or inference, ideal for initial setup"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"before_epoch\" class=\"doc_header\"><code>before_epoch</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the beginning of each epoch, useful for any behavior you need to reset at each epoch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"before_train\" class=\"doc_header\"><code>before_train</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the beginning of each training part of an epoch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"before_batch\" class=\"doc_header\"><code>before_batch</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_pred\" class=\"doc_header\"><code>after_pred</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_loss\" class=\"doc_header\"><code>after_loss</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"before_backward\" class=\"doc_header\"><code>before_backward</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"before_step\" class=\"doc_header\"><code>before_step</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_step\" class=\"doc_header\"><code>after_step</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called after the step and before the gradients are zeroed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_batch\" class=\"doc_header\"><code>after_batch</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the end of a batch, for any clean-up before the next one."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_cancel_train\" class=\"doc_header\"><code>after_cancel_train</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Reached immediately after a `CancelTrainException` before proceeding to `after_epoch`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_train\" class=\"doc_header\"><code>after_train</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the end of the training phase of an epoch."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"before_validate\" class=\"doc_header\"><code>before_validate</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_cancel_validate\" class=\"doc_header\"><code>after_cancel_validate</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Reached immediately after a `CancelValidException` before proceeding to `after_epoch`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_validate\" class=\"doc_header\"><code>after_validate</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the end of the validation part of an epoch."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_cancel_epoch\" class=\"doc_header\"><code>after_cancel_epoch</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Reached immediately after a `CancelEpochException` before proceeding to `after_epoch`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_epoch\" class=\"doc_header\"><code>after_epoch</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the end of an epoch, for any clean-up before the next one."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_cancel_fit\" class=\"doc_header\"><code>after_cancel_fit</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Reached immediately after a `CancelFitException` before proceeding to `after_fit`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"after_fit\" class=\"doc_header\"><code>after_fit</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Called at the end of training, for final clean-up."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "for event in Events: \n",
    "    show_doc(event, title_level=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7968ef-9f9b-40ad-8c4a-fb06a7601556",
   "metadata": {},
   "source": [
    "## Callback -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962ce87-7c4b-4db6-b217-b2c03da5dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_inner_loop = \"before_batch after_pred after_loss before_backward before_step after_step after_cancel_batch after_batch\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434397e-4fd7-4b27-b4ac-0e2cd275d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@funcs_kwargs(as_method=True)\n",
    "class Callback(Stateful,GetAttr):\n",
    "    \"\"\"\n",
    "    Basic class handling tweaks of the training loop by changing a `Learner` in various events.\n",
    "    \n",
    "    To use, implement any supported event in `Events` that should be called. \n",
    "    An `order` can be passed to dictate its call priority\n",
    "    \"\"\"\n",
    "    order,_default,learn,run,run_train,run_valid = 0,'learn',None,True,True,True\n",
    "    _methods = [e.name for e in Events]\n",
    "\n",
    "    def __init__(self, **kwargs): assert not kwargs, f'Passed unknown events: {kwargs}'\n",
    "    def __repr__(self): return type(self).__name__\n",
    "\n",
    "    def __call__(self, event_name):\n",
    "        \"Call `self.{event_name}` if it's defined\"\n",
    "        _run = (event_name not in _inner_loop or (self.run_train and getattr(self, 'training', True)) or\n",
    "               (self.run_valid and not getattr(self, 'training', False)))\n",
    "        res = None\n",
    "        if self.run and _run: \n",
    "            try:\n",
    "                res = getattr(self, event_name, noop)()\n",
    "            except Exception as e:\n",
    "                e.args = [f'Exception occured when calling event `{event_name}` in `{self.name}`:\\n\\t{e.args[0]}']\n",
    "                raise e\n",
    "        if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit\n",
    "        return res\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if hasattr(self.learn,name):\n",
    "            warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n",
    "        super().__setattr__(name, value)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        \"Name of the `Callback`, camel-cased and with '*Callback*' removed\"\n",
    "        return class2attr(self, 'Callback').title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce1d78-ce25-4a02-b542-5ab14475769e",
   "metadata": {},
   "source": [
    "One way to define callbacks is through subclassing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f695030-4db0-48a8-8489-fd0d91145d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(Callback):\n",
    "    def call_me(self): return \"maybe\"\n",
    "test_eq(_T()(\"call_me\"), \"maybe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2493b29-ff46-4422-aa71-bf2453df70af",
   "metadata": {},
   "source": [
    "Another way is by passing the callback function to the constructor:\n",
    "> Note: Notice that the `cb` still has `self` as a parameter. It is considered a class function we assign in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e061e4-fe61-44ba-978d-9b8c1e831fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb(self): return \"maybe\"\n",
    "_t = Callback(before_fit=cb)\n",
    "test_eq(_t(Events.before_fit), \"maybe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72a9b3-1bf4-4dc2-98c9-137807695135",
   "metadata": {},
   "source": [
    "`Callback` provides a shortcut to avoid having to write `self.learn.bla` for any `bla` attribute we seek on `Learner`; instead just write `self.bla`.\n",
    "> Note: This only works for **getting** attributes, *not* for setting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b46885-3f09-45b0-9378-24e45b99531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_class('TstLearner', 'a')\n",
    "\n",
    "class TstCallback(Callback):\n",
    "    def batch_begin(self): print(self.a)\n",
    "\n",
    "learn,cb = TstLearner(1),TstCallback()\n",
    "cb.learn = learn\n",
    "test_stdout(lambda: cb('batch_begin'), \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24dea6-fe83-456e-aff7-352555bbbee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
